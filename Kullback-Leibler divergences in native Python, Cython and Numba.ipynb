{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></div><div class=\"lev1 toc-item\"><a href=\"#KL-divergences-and-KL-UCB-indexes,-in-naive-Python\" data-toc-modified-id=\"KL-divergences-and-KL-UCB-indexes,-in-naive-Python-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>KL divergences and KL-UCB indexes, in naive Python</a></div><div class=\"lev2 toc-item\"><a href=\"#KL-divergences\" data-toc-modified-id=\"KL-divergences-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>KL divergences</a></div><div class=\"lev3 toc-item\"><a href=\"#Bernoulli-distributions\" data-toc-modified-id=\"Bernoulli-distributions-211\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Bernoulli distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Binomial-distributions\" data-toc-modified-id=\"Binomial-distributions-212\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Binomial distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Poisson-distributions\" data-toc-modified-id=\"Poisson-distributions-213\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Poisson distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Exponential-distributions\" data-toc-modified-id=\"Exponential-distributions-214\"><span class=\"toc-item-num\">2.1.4&nbsp;&nbsp;</span>Exponential distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Gamma-distributions\" data-toc-modified-id=\"Gamma-distributions-215\"><span class=\"toc-item-num\">2.1.5&nbsp;&nbsp;</span>Gamma distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Negative-binomial-distributions\" data-toc-modified-id=\"Negative-binomial-distributions-216\"><span class=\"toc-item-num\">2.1.6&nbsp;&nbsp;</span>Negative binomial distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Gaussian-distributions\" data-toc-modified-id=\"Gaussian-distributions-217\"><span class=\"toc-item-num\">2.1.7&nbsp;&nbsp;</span>Gaussian distributions</a></div><div class=\"lev2 toc-item\"><a href=\"#Generic-KL-UCB-indexes,-with-a-bisection-search\" data-toc-modified-id=\"Generic-KL-UCB-indexes,-with-a-bisection-search-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Generic KL-UCB indexes, with a bisection search</a></div><div class=\"lev2 toc-item\"><a href=\"#Distribution-specific-KL-UCB-indexes\" data-toc-modified-id=\"Distribution-specific-KL-UCB-indexes-23\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Distribution-specific KL-UCB indexes</a></div><div class=\"lev3 toc-item\"><a href=\"#Gaussian\" data-toc-modified-id=\"Gaussian-231\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Gaussian</a></div><div class=\"lev3 toc-item\"><a href=\"#Bernoulli\" data-toc-modified-id=\"Bernoulli-232\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Bernoulli</a></div><div class=\"lev3 toc-item\"><a href=\"#Poisson\" data-toc-modified-id=\"Poisson-233\"><span class=\"toc-item-num\">2.3.3&nbsp;&nbsp;</span>Poisson</a></div><div class=\"lev3 toc-item\"><a href=\"#Exponential\" data-toc-modified-id=\"Exponential-234\"><span class=\"toc-item-num\">2.3.4&nbsp;&nbsp;</span>Exponential</a></div><div class=\"lev3 toc-item\"><a href=\"#Others\" data-toc-modified-id=\"Others-235\"><span class=\"toc-item-num\">2.3.5&nbsp;&nbsp;</span>Others</a></div><div class=\"lev1 toc-item\"><a href=\"#With-Numba\" data-toc-modified-id=\"With-Numba-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>With Numba</a></div><div class=\"lev2 toc-item\"><a href=\"#KL-divergences\" data-toc-modified-id=\"KL-divergences-31\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>KL divergences</a></div><div class=\"lev3 toc-item\"><a href=\"#Bernoulli-distributions\" data-toc-modified-id=\"Bernoulli-distributions-311\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Bernoulli distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Binomial-distributions\" data-toc-modified-id=\"Binomial-distributions-312\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Binomial distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Poisson-distributions\" data-toc-modified-id=\"Poisson-distributions-313\"><span class=\"toc-item-num\">3.1.3&nbsp;&nbsp;</span>Poisson distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Exponential-distributions\" data-toc-modified-id=\"Exponential-distributions-314\"><span class=\"toc-item-num\">3.1.4&nbsp;&nbsp;</span>Exponential distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Gamma-distributions\" data-toc-modified-id=\"Gamma-distributions-315\"><span class=\"toc-item-num\">3.1.5&nbsp;&nbsp;</span>Gamma distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Negative-binomial-distributions\" data-toc-modified-id=\"Negative-binomial-distributions-316\"><span class=\"toc-item-num\">3.1.6&nbsp;&nbsp;</span>Negative binomial distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Gaussian-distributions\" data-toc-modified-id=\"Gaussian-distributions-317\"><span class=\"toc-item-num\">3.1.7&nbsp;&nbsp;</span>Gaussian distributions</a></div><div class=\"lev2 toc-item\"><a href=\"#Generic-KL-UCB-indexes,-with-a-bisection-search\" data-toc-modified-id=\"Generic-KL-UCB-indexes,-with-a-bisection-search-32\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Generic KL-UCB indexes, with a bisection search</a></div><div class=\"lev2 toc-item\"><a href=\"#Distribution-specific-KL-UCB-indexes\" data-toc-modified-id=\"Distribution-specific-KL-UCB-indexes-33\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Distribution-specific KL-UCB indexes</a></div><div class=\"lev3 toc-item\"><a href=\"#Gaussian\" data-toc-modified-id=\"Gaussian-331\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>Gaussian</a></div><div class=\"lev3 toc-item\"><a href=\"#Bernoulli\" data-toc-modified-id=\"Bernoulli-332\"><span class=\"toc-item-num\">3.3.2&nbsp;&nbsp;</span>Bernoulli</a></div><div class=\"lev3 toc-item\"><a href=\"#Poisson\" data-toc-modified-id=\"Poisson-333\"><span class=\"toc-item-num\">3.3.3&nbsp;&nbsp;</span>Poisson</a></div><div class=\"lev3 toc-item\"><a href=\"#Exponential\" data-toc-modified-id=\"Exponential-334\"><span class=\"toc-item-num\">3.3.4&nbsp;&nbsp;</span>Exponential</a></div><div class=\"lev1 toc-item\"><a href=\"#With-Cython\" data-toc-modified-id=\"With-Cython-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>With Cython</a></div><div class=\"lev2 toc-item\"><a href=\"#KL-divergences\" data-toc-modified-id=\"KL-divergences-41\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>KL divergences</a></div><div class=\"lev3 toc-item\"><a href=\"#Bernoulli-distributions\" data-toc-modified-id=\"Bernoulli-distributions-411\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Bernoulli distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Binomial-distributions\" data-toc-modified-id=\"Binomial-distributions-412\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>Binomial distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Poisson-distributions\" data-toc-modified-id=\"Poisson-distributions-413\"><span class=\"toc-item-num\">4.1.3&nbsp;&nbsp;</span>Poisson distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Exponential-distributions\" data-toc-modified-id=\"Exponential-distributions-414\"><span class=\"toc-item-num\">4.1.4&nbsp;&nbsp;</span>Exponential distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Gamma-distributions\" data-toc-modified-id=\"Gamma-distributions-415\"><span class=\"toc-item-num\">4.1.5&nbsp;&nbsp;</span>Gamma distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Negative-binomial-distributions\" data-toc-modified-id=\"Negative-binomial-distributions-416\"><span class=\"toc-item-num\">4.1.6&nbsp;&nbsp;</span>Negative binomial distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Gaussian-distributions\" data-toc-modified-id=\"Gaussian-distributions-417\"><span class=\"toc-item-num\">4.1.7&nbsp;&nbsp;</span>Gaussian distributions</a></div><div class=\"lev2 toc-item\"><a href=\"#Generic-KL-UCB-indexes,-with-a-bisection-search\" data-toc-modified-id=\"Generic-KL-UCB-indexes,-with-a-bisection-search-42\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Generic KL-UCB indexes, with a bisection search</a></div><div class=\"lev1 toc-item\"><a href=\"#Benchmarks\" data-toc-modified-id=\"Benchmarks-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Benchmarks</a></div><div class=\"lev2 toc-item\"><a href=\"#KL-divergences\" data-toc-modified-id=\"KL-divergences-51\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>KL divergences</a></div><div class=\"lev3 toc-item\"><a href=\"#Bernoulli\" data-toc-modified-id=\"Bernoulli-511\"><span class=\"toc-item-num\">5.1.1&nbsp;&nbsp;</span>Bernoulli</a></div><div class=\"lev3 toc-item\"><a href=\"#Binomial\" data-toc-modified-id=\"Binomial-512\"><span class=\"toc-item-num\">5.1.2&nbsp;&nbsp;</span>Binomial</a></div><div class=\"lev3 toc-item\"><a href=\"#Poisson\" data-toc-modified-id=\"Poisson-513\"><span class=\"toc-item-num\">5.1.3&nbsp;&nbsp;</span>Poisson</a></div><div class=\"lev3 toc-item\"><a href=\"#Exponential\" data-toc-modified-id=\"Exponential-514\"><span class=\"toc-item-num\">5.1.4&nbsp;&nbsp;</span>Exponential</a></div><div class=\"lev3 toc-item\"><a href=\"#Binomial\" data-toc-modified-id=\"Binomial-515\"><span class=\"toc-item-num\">5.1.5&nbsp;&nbsp;</span>Binomial</a></div><div class=\"lev3 toc-item\"><a href=\"#Binomial\" data-toc-modified-id=\"Binomial-516\"><span class=\"toc-item-num\">5.1.6&nbsp;&nbsp;</span>Binomial</a></div><div class=\"lev3 toc-item\"><a href=\"#Negative-binomial\" data-toc-modified-id=\"Negative-binomial-517\"><span class=\"toc-item-num\">5.1.7&nbsp;&nbsp;</span>Negative binomial</a></div><div class=\"lev2 toc-item\"><a href=\"#KL-UCB-indexes\" data-toc-modified-id=\"KL-UCB-indexes-52\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>KL-UCB indexes</a></div><div class=\"lev3 toc-item\"><a href=\"#Gaussian\" data-toc-modified-id=\"Gaussian-521\"><span class=\"toc-item-num\">5.2.1&nbsp;&nbsp;</span>Gaussian</a></div><div class=\"lev3 toc-item\"><a href=\"#Bernoulli\" data-toc-modified-id=\"Bernoulli-522\"><span class=\"toc-item-num\">5.2.2&nbsp;&nbsp;</span>Bernoulli</a></div><div class=\"lev3 toc-item\"><a href=\"#Poisson\" data-toc-modified-id=\"Poisson-523\"><span class=\"toc-item-num\">5.2.3&nbsp;&nbsp;</span>Poisson</a></div><div class=\"lev3 toc-item\"><a href=\"#Exponential\" data-toc-modified-id=\"Exponential-524\"><span class=\"toc-item-num\">5.2.4&nbsp;&nbsp;</span>Exponential</a></div><div class=\"lev1 toc-item\"><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Conclusion</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Introduction\n",
    "\n",
    "In this small notebook, I implement various [Kullback-Leibler divergence functions](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence), in [Python](https://www.python.org/), using different approaches: naive Python, and using Numba and Cython.\n",
    "\n",
    "I also implement KL-UCB indexes, in the three approaches, and finally I present some basic benchmarks to compare the time and memory efficiency of the different approaches, for each function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "Lilian Besson (Naereen) \n",
      "\n",
      "CPython 3.6.3\n",
      "IPython 6.3.1\n",
      "\n",
      "numpy 1.14.2\n",
      "numba 0.37.0\n",
      "\n",
      "compiler   : GCC 7.2.0\n",
      "system     : Linux\n",
      "release    : 4.13.0-38-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n",
      "Git hash   : 06833391fef4f12f207a3fbec76bbc37ce81c6ec\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -m -a \"Lilian Besson (Naereen)\" -p numpy,numba -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# KL divergences and KL-UCB indexes, in naive Python\n",
    "\n",
    "I will copy and paste parts of [this file](https://github.com/SMPyBandits/SMPyBandits/blob/master/SMPyBandits/Policies/kullback.py) from my [SMPyBandits](https://github.com/SMPyBandits/SMPyBandits/) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-15  #: Threshold value: everything in [0, 1] is truncated to [eps, 1 - eps]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will include docstrings and examples only for the naive implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KL divergences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def klBern(x, y):\n",
    "    r\"\"\" Kullback-Leibler divergence for Bernoulli distributions. https://en.wikipedia.org/wiki/Bernoulli_distribution#Kullback.E2.80.93Leibler_divergence\n",
    "\n",
    "    .. math:: \\mathrm{KL}(\\mathcal{B}(x), \\mathcal{B}(y)) = x \\log(\\frac{x}{y}) + (1-x) \\log(\\frac{1-x}{1-y}).\"\"\"\n",
    "    x = min(max(x, eps), 1 - eps)\n",
    "    y = min(max(y, eps), 1 - eps)\n",
    "    return x * np.log(x / y) + (1 - x) * np.log((1 - x) / (1 - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.7577796618689758"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.7577796618689758"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.020135513550688863"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4.503217453131898"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "34.53957599234081"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klBern(0.5, 0.5)\n",
    "klBern(0.1, 0.9)\n",
    "klBern(0.9, 0.1)\n",
    "klBern(0.4, 0.5)\n",
    "klBern(0.01, 0.99)\n",
    "klBern(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def klBin(x, y, n):\n",
    "    r\"\"\" Kullback-Leibler divergence for Binomial distributions. https://math.stackexchange.com/questions/320399/kullback-leibner-divergence-of-binomial-distributions\n",
    "\n",
    "    - It is simply the n times :func:`klBern` on x and y.\n",
    "\n",
    "    .. math:: \\mathrm{KL}(\\mathrm{Bin}(x, n), \\mathrm{Bin}(y, n)) = n \\times \\left(x \\log(\\frac{x}{y}) + (1-x) \\log(\\frac{1-x}{1-y}) \\right).\n",
    "\n",
    "    .. warning:: The two distributions must have the same parameter n, and x, y are p, q in (0, 1).\n",
    "    \"\"\"\n",
    "    x = min(max(x, eps), 1 - eps)\n",
    "    y = min(max(y, eps), 1 - eps)\n",
    "    return n * (x * np.log(x / y) + (1 - x) * np.log((1 - x) / (1 - y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "17.57779661868976"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "17.57779661868976"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.20135513550688863"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "45.03217453131897"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "345.3957599234081"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klBin(0.5, 0.5, 10)\n",
    "klBin(0.1, 0.9, 10)\n",
    "klBin(0.9, 0.1, 10)\n",
    "klBin(0.4, 0.5, 10)\n",
    "klBin(0.01, 0.99, 10)\n",
    "klBin(0, 1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def klPoisson(x, y):\n",
    "    r\"\"\" Kullback-Leibler divergence for Poison distributions. https://en.wikipedia.org/wiki/Poisson_distribution#Kullback.E2.80.93Leibler_divergence\n",
    "\n",
    "    .. math:: \\mathrm{KL}(\\mathrm{Poisson}(x), \\mathrm{Poisson}(y)) = y - x + x \\times \\log(\\frac{x}{y}).\n",
    "    \"\"\"\n",
    "    x = max(x, eps)\n",
    "    y = max(y, eps)\n",
    "    return y - x + x * np.log(x / y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.3862943611198906"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.3068528194400547"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9205584583201643"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.2739075652893146"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "33.538776394910684"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klPoisson(3, 3)\n",
    "klPoisson(2, 1)\n",
    "klPoisson(1, 2)\n",
    "klPoisson(3, 6)\n",
    "klPoisson(6, 8)\n",
    "klPoisson(1, 0)\n",
    "klPoisson(0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def klExp(x, y):\n",
    "    r\"\"\" Kullback-Leibler divergence for exponential distributions. https://en.wikipedia.org/wiki/Exponential_distribution#Kullback.E2.80.93Leibler_divergence\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        \\mathrm{KL}(\\mathrm{Exp}(x), \\mathrm{Exp}(y)) = \\begin{cases}\n",
    "        \\frac{x}{y} - 1 - \\log(\\frac{x}{y}) & \\text{if} x > 0, y > 0\\\\\n",
    "        +\\infty & \\text{otherwise}\n",
    "        \\end{cases}\n",
    "    \"\"\"\n",
    "    if x <= 0 or y <= 0:\n",
    "        return float('+inf')\n",
    "    else:\n",
    "        x = max(x, eps)\n",
    "        y = max(y, eps)\n",
    "        return x / y - 1 - np.log(x / y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.1931471805599453"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.1931471805599453"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.3068528194400547"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.3068528194400547"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0376820724517809"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klExp(3, 3)\n",
    "klExp(3, 6)\n",
    "klExp(1, 2)\n",
    "klExp(2, 1)\n",
    "klExp(4, 2)\n",
    "klExp(6, 8)\n",
    "klExp(-3, 2)\n",
    "klExp(3, -2)\n",
    "klExp(-3, -2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gamma distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def klGamma(x, y, a=1):\n",
    "    r\"\"\" Kullback-Leibler divergence for gamma distributions. https://en.wikipedia.org/wiki/Gamma_distribution#Kullback.E2.80.93Leibler_divergence\n",
    "\n",
    "    - It is simply the a times :func:`klExp` on x and y.\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        \\mathrm{KL}(\\Gamma(x, a), \\Gamma(y, a)) = \\begin{cases}\n",
    "        a \\times \\left( \\frac{x}{y} - 1 - \\log(\\frac{x}{y}) \\right) & \\text{if} x > 0, y > 0\\\\\n",
    "        +\\infty & \\text{otherwise}\n",
    "        \\end{cases}\n",
    "\n",
    "    .. warning:: The two distributions must have the same parameter a.\n",
    "    \"\"\"\n",
    "    if x <= 0 or y <= 0:\n",
    "        return float('+inf')\n",
    "    else:\n",
    "        x = max(x, eps)\n",
    "        y = max(y, eps)\n",
    "        return a * (x / y - 1 - np.log(x / y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.1931471805599453"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.1931471805599453"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.3068528194400547"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.3068528194400547"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0376820724517809"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klGamma(3, 3)\n",
    "klGamma(3, 6)\n",
    "klGamma(1, 2)\n",
    "klGamma(2, 1)\n",
    "klGamma(4, 2)\n",
    "klGamma(6, 8)\n",
    "klGamma(-3, 2)\n",
    "klGamma(3, -2)\n",
    "klGamma(-3, -2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative binomial distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def klNegBin(x, y, r=1):\n",
    "    r\"\"\" Kullback-Leibler divergence for negative binomial distributions. https://en.wikipedia.org/wiki/Negative_binomial_distribution\n",
    "\n",
    "    .. math:: \\mathrm{KL}(\\mathrm{NegBin}(x, r), \\mathrm{NegBin}(y, r)) = r \\times \\log((r + x) / (r + y)) - x \\times \\log(y \\times (r + x) / (x \\times (r + y))).\n",
    "\n",
    "    .. warning:: The two distributions must have the same parameter r.\n",
    "    \"\"\"\n",
    "    x = max(x, eps)\n",
    "    y = max(y, eps)\n",
    "    return r * np.log((r + x) / (r + y)) - x * np.log(y * (r + x) / (x * (r + y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-0.7116117934648849"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2.0321564902394043"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-0.13065314341785483"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-0.7173536633057466"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "34.53957599234081"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-0.8329919030334189"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-0.9148905602182661"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2.332552851091954"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-0.15457261175809217"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-0.8362571425112515"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klNegBin(0.5, 0.5)\n",
    "klNegBin(0.1, 0.9)\n",
    "klNegBin(0.9, 0.1)\n",
    "klNegBin(0.4, 0.5)\n",
    "klNegBin(0.01, 0.99)\n",
    "klBern(0, 1)\n",
    "klNegBin(0.5, 0.5, r=2)\n",
    "klNegBin(0.1, 0.9, r=2)\n",
    "klNegBin(0.1, 0.9, r=4)\n",
    "klNegBin(0.9, 0.1, r=2)\n",
    "klNegBin(0.4, 0.5, r=2)\n",
    "klNegBin(0.01, 0.99, r=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def klGauss(x, y, sig2x=0.25, sig2y=None):\n",
    "    r\"\"\" Kullback-Leibler divergence for Gaussian distributions of means ``x`` and ``y`` and variances ``sig2x`` and ``sig2y``, :math:`\\nu_1 = \\mathcal{N}(x, \\sigma_x^2)` and :math:`\\nu_2 = \\mathcal{N}(y, \\sigma_x^2)`:\n",
    "\n",
    "    .. math:: \\mathrm{KL}(\\nu_1, \\nu_2) = \\frac{(x - y)^2}{2 \\sigma_y^2} + \\frac{1}{2}\\left( \\frac{\\sigma_x^2}{\\sigma_y^2} - 1 \\log\\left(\\frac{\\sigma_x^2}{\\sigma_y^2}\\right) \\right).\n",
    "\n",
    "    See https://en.wikipedia.org/wiki/Normal_distribution#Other_properties\n",
    "\n",
    "    - By default, sig2y is assumed to be sig2x (same variance).\n",
    "    \"\"\"\n",
    "    if sig2y is None or - eps < (sig2y - sig2x) < eps:\n",
    "        return (x - y) ** 2 / (2. * sig2x)\n",
    "    else:\n",
    "        return (x - y) ** 2 / (2. * sig2y) + 0.5 * ((sig2x/sig2y)**2 - 1 - np.log(sig2x/sig2y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "18.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.45"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.05"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.05"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-0.028426409720027357"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.2243971805599453"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.1534264097200273"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9715735902799727"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7243971805599453"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3.1534264097200273"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9715735902799727"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7243971805599453"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3.1534264097200273"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klGauss(3, 3)\n",
    "klGauss(3, 6)\n",
    "klGauss(1, 2)\n",
    "klGauss(2, 1)\n",
    "klGauss(4, 2)\n",
    "klGauss(6, 8)\n",
    "klGauss(-3, 2)\n",
    "klGauss(3, -2)\n",
    "klGauss(-3, -2)\n",
    "klGauss(3, 2)\n",
    "klGauss(3, 3, sig2x=10)\n",
    "klGauss(3, 6, sig2x=10)\n",
    "klGauss(1, 2, sig2x=10)\n",
    "klGauss(2, 1, sig2x=10)\n",
    "klGauss(4, 2, sig2x=10)\n",
    "klGauss(6, 8, sig2x=10)\n",
    "klGauss(0, 0, sig2x=0.25, sig2y=0.5)\n",
    "klGauss(0, 0, sig2x=0.25, sig2y=1.0)\n",
    "klGauss(0, 0, sig2x=0.5, sig2y=0.25)\n",
    "klGauss(0, 1, sig2x=0.25, sig2y=0.5)\n",
    "klGauss(0, 1, sig2x=0.25, sig2y=1.0)\n",
    "klGauss(0, 1, sig2x=0.5, sig2y=0.25)\n",
    "klGauss(1, 0, sig2x=0.25, sig2y=0.5)\n",
    "klGauss(1, 0, sig2x=0.25, sig2y=1.0)\n",
    "klGauss(1, 0, sig2x=0.5, sig2y=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic KL-UCB indexes, with a bisection search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def klucb(x, d, kl, upperbound, lowerbound=float('-inf'), precision=1e-6, max_iterations=50):\n",
    "    \"\"\" The generic KL-UCB index computation.\n",
    "\n",
    "    - x: value of the cum reward,\n",
    "    - d: upper bound on the divergence,\n",
    "    - kl: the KL divergence to be used (:func:`klBern`, :func:`klGauss`, etc),\n",
    "    - upperbound, lowerbound=float('-inf'): the known bound of the values x,\n",
    "    - precision=1e-6: the threshold from where to stop the research,\n",
    "    - max_iterations: max number of iterations of the loop (safer to bound it to reduce time complexity).\n",
    "\n",
    "    .. note:: It uses a **bisection search**, and one call to ``kl`` for each step of the bisection search.\n",
    "    \"\"\"\n",
    "    value = max(x, lowerbound)\n",
    "    u = upperbound\n",
    "    _count_iteration = 0\n",
    "    while _count_iteration < max_iterations and u - value > precision:\n",
    "        _count_iteration += 1\n",
    "        m = (value + u) / 2.\n",
    "        if kl(x, m) > d:\n",
    "            u = m\n",
    "        else:\n",
    "            value = m\n",
    "    return (value + u) / 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, for `klucbBern`, the two steps are to first compute an upperbound (as precise as possible) and the compute the kl-UCB index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.994140625"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9944824218750001"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.994140625"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9944896697998048"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, d = 0.9, 0.2\n",
    "upperbound = 1\n",
    "klucb(x, d, klBern, upperbound, lowerbound=0, precision=1e-3, max_iterations=10)\n",
    "klucb(x, d, klBern, upperbound, lowerbound=0, precision=1e-6, max_iterations=10)\n",
    "klucb(x, d, klBern, upperbound, lowerbound=0, precision=1e-3, max_iterations=50)\n",
    "klucb(x, d, klBern, upperbound, lowerbound=0, precision=1e-6, max_iterations=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution-specific KL-UCB indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def klucbGauss(x, d, sig2x=0.25, precision=0.):\n",
    "    \"\"\" KL-UCB index computation for Gaussian distributions.\n",
    "\n",
    "    - Note that it does not require any search.\n",
    "\n",
    "    .. warning:: it works only if the good variance constant is given.\n",
    "    \"\"\"\n",
    "    return x + np.sqrt(2 * sig2x * d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.416227766016838"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.816227766016838"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.216227766016838"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.547213595499958"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7708203932499369"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9472135954999579"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.170820393249937"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.347213595499958"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.570820393249937"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klucbGauss(0.1, 0.2)\n",
    "klucbGauss(0.5, 0.2)\n",
    "klucbGauss(0.9, 0.2)\n",
    "klucbGauss(0.1, 0.4)\n",
    "klucbGauss(0.1, 0.9)\n",
    "klucbGauss(0.5, 0.4)\n",
    "klucbGauss(0.5, 0.9)\n",
    "klucbGauss(0.9, 0.4)\n",
    "klucbGauss(0.9, 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def klucbBern(x, d, precision=1e-6):\n",
    "    \"\"\" KL-UCB index computation for Bernoulli distributions, using :func:`klucb`.\"\"\"\n",
    "    upperbound = min(1., klucbGauss(x, d, sig2x=0.25))  # variance 1/4 for [0,1] bounded distributions\n",
    "    # upperbound = min(1., klucbPoisson(x, d))  # also safe, and better ?\n",
    "    return klucb(x, d, klBern, upperbound, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37839145109809247"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7870889692292777"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9944896697998048"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.5194755673450786"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7347148310932183"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.871035844022684"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9568095207214355"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9992855072021485"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9999950408935546"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klucbBern(0.1, 0.2)\n",
    "klucbBern(0.5, 0.2)\n",
    "klucbBern(0.9, 0.2)\n",
    "klucbBern(0.1, 0.4)\n",
    "klucbBern(0.1, 0.9)\n",
    "klucbBern(0.5, 0.4)\n",
    "klucbBern(0.5, 0.9)\n",
    "klucbBern(0.9, 0.4)\n",
    "klucbBern(0.9, 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def klucbPoisson(x, d, precision=1e-6):\n",
    "    \"\"\" KL-UCB index computation for Poisson distributions, using :func:`klucb`.\"\"\"\n",
    "    upperbound = x + d + np.sqrt(d * d + 2 * x * d)  # looks safe, to check: left (Gaussian) tail of Poisson dev\n",
    "    return klucb(x, d, klPoisson, upperbound, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45052392780119604"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.0893765430263218"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.6401128559741487"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.6936844019642616"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.2527967047658155"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.4229339603816749"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2.122985165630671"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2.033691887156203"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2.8315738094979777"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klucbPoisson(0.1, 0.2)\n",
    "klucbPoisson(0.5, 0.2)\n",
    "klucbPoisson(0.9, 0.2)\n",
    "klucbPoisson(0.1, 0.4)\n",
    "klucbPoisson(0.1, 0.9)\n",
    "klucbPoisson(0.5, 0.4)\n",
    "klucbPoisson(0.5, 0.9)\n",
    "klucbPoisson(0.9, 0.4)\n",
    "klucbPoisson(0.9, 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def klucbExp(x, d, precision=1e-6):\n",
    "    \"\"\" KL-UCB index computation for exponential distributions, using :func:`klucb`.\"\"\"\n",
    "    if d < 0.77:  # XXX where does this value come from?\n",
    "        upperbound = x / (1 + 2. / 3 * d - np.sqrt(4. / 9 * d * d + 2 * d))\n",
    "        # safe, klexp(x,y) >= e^2/(2*(1-2e/3)) if x=y(1-e)\n",
    "    else:\n",
    "        upperbound = x * np.exp(d + 1)\n",
    "    if d > 1.61:  # XXX where does this value come from?\n",
    "        lowerbound = x * np.exp(d)\n",
    "    else:\n",
    "        lowerbound = x / (1 + d - np.sqrt(d * d + 2 * d))\n",
    "    return klucb(x, d, klGamma, upperbound, lowerbound, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20274118449172676"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.013706285168157"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.8246716397412546"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.2857928251730546"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.5590884945251575"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.428962647183463"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2.7954420946912126"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2.572132498767508"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5.031795430303065"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klucbExp(0.1, 0.2)\n",
    "klucbExp(0.5, 0.2)\n",
    "klucbExp(0.9, 0.2)\n",
    "klucbExp(0.1, 0.4)\n",
    "klucbExp(0.1, 0.9)\n",
    "klucbExp(0.5, 0.4)\n",
    "klucbExp(0.5, 0.9)\n",
    "klucbExp(0.9, 0.4)\n",
    "klucbExp(0.9, 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Others\n",
    "We could do the same for more distributions, but that's enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# With Numba\n",
    "\n",
    "It will be *exactly* the same code as above, except that the [`numba.jit`](http://numba.pydata.org/numba-doc/latest/user/jit.html) decorator will be used for each functions, to let [numba](http://numba.pydata.org/) *try* to speed up the code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KL divergences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def klBern_numba(x, y):\n",
    "    x = min(max(x, eps), 1 - eps)\n",
    "    y = min(max(y, eps), 1 - eps)\n",
    "    return x * np.log(x / y) + (1 - x) * np.log((1 - x) / (1 - y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def klBin_numba(x, y, n):\n",
    "    x = min(max(x, eps), 1 - eps)\n",
    "    y = min(max(y, eps), 1 - eps)\n",
    "    return n * (x * np.log(x / y) + (1 - x) * np.log((1 - x) / (1 - y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def klPoisson_numba(x, y):\n",
    "    x = max(x, eps)\n",
    "    y = max(y, eps)\n",
    "    return y - x + x * np.log(x / y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def klExp_numba(x, y):\n",
    "    if x <= 0 or y <= 0:\n",
    "        return float('+inf')\n",
    "    else:\n",
    "        x = max(x, eps)\n",
    "        y = max(y, eps)\n",
    "        return x / y - 1 - np.log(x / y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gamma distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def klGamma_numba(x, y, a=1):\n",
    "    if x <= 0 or y <= 0:\n",
    "        return float('+inf')\n",
    "    else:\n",
    "        x = max(x, eps)\n",
    "        y = max(y, eps)\n",
    "        return a * (x / y - 1 - np.log(x / y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative binomial distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def klNegBin_numba(x, y, r=1):\n",
    "    x = max(x, eps)\n",
    "    y = max(y, eps)\n",
    "    return r * np.log((r + x) / (r + y)) - x * np.log(y * (r + x) / (x * (r + y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def klGauss_numba(x, y, sig2x=0.25, sig2y=None):\n",
    "    if sig2y is None or - eps < (sig2y - sig2x) < eps:\n",
    "        return (x - y) ** 2 / (2. * sig2x)\n",
    "    else:\n",
    "        return (x - y) ** 2 / (2. * sig2y) + 0.5 * ((sig2x/sig2y)**2 - 1 - np.log(sig2x/sig2y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic KL-UCB indexes, with a bisection search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def klucb_numba(x, d, kl, upperbound, lowerbound=float('-inf'), precision=1e-6, max_iterations=50):\n",
    "    value = max(x, lowerbound)\n",
    "    u = upperbound\n",
    "    _count_iteration = 0\n",
    "    while _count_iteration < max_iterations and u - value > precision:\n",
    "        _count_iteration += 1\n",
    "        m = (value + u) / 2.\n",
    "        if kl(x, m) > d:\n",
    "            u = m\n",
    "        else:\n",
    "            value = m\n",
    "    return (value + u) / 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, for `klucbBern`, the two steps are to first compute an upperbound (as precise as possible) and the compute the kl-UCB index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.994140625"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9944824218750001"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.994140625"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9944896697998048"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, d = 0.9, 0.2\n",
    "upperbound = 1\n",
    "klucb_numba(x, d, klBern_numba, upperbound, lowerbound=0, precision=1e-3, max_iterations=10)\n",
    "klucb_numba(x, d, klBern_numba, upperbound, lowerbound=0, precision=1e-6, max_iterations=10)\n",
    "klucb_numba(x, d, klBern_numba, upperbound, lowerbound=0, precision=1e-3, max_iterations=50)\n",
    "klucb_numba(x, d, klBern_numba, upperbound, lowerbound=0, precision=1e-6, max_iterations=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution-specific KL-UCB indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def klucbGauss_numba(x, d, sig2x=0.25, precision=0.):\n",
    "    return x + np.sqrt(2 * sig2x * d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def klucbBern_numba(x, d, precision=1e-6):\n",
    "    upperbound = min(1., klucbGauss_numba(x, d, sig2x=0.25))  # variance 1/4 for [0,1] bounded distributions\n",
    "    # upperbound = min(1., klucbPoisson(x, d))  # also safe, and better ?\n",
    "    return klucb_numba(x, d, klBern_numba, upperbound, precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def klucbPoisson_numba(x, d, precision=1e-6):\n",
    "    upperbound = x + d + np.sqrt(d * d + 2 * x * d)  # looks safe, to check: left (Gaussian) tail of Poisson dev\n",
    "    return klucb_numba(x, d, klPoisson_numba, upperbound, precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def klucbExp_numba(x, d, precision=1e-6):\n",
    "    if d < 0.77:  # XXX where does this value come from?\n",
    "        upperbound = x / (1 + 2. / 3 * d - np.sqrt(4. / 9 * d * d + 2 * d))\n",
    "        # safe, klexp(x,y) >= e^2/(2*(1-2e/3)) if x=y(1-e)\n",
    "    else:\n",
    "        upperbound = x * np.exp(d + 1)\n",
    "    if d > 1.61:  # XXX where does this value come from?\n",
    "        lowerbound = x * np.exp(d)\n",
    "    else:\n",
    "        lowerbound = x / (1 + d - np.sqrt(d * d + 2 * d))\n",
    "    return klucb_numba(x, d, klGamma_numba, upperbound, lowerbound, precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# With Cython\n",
    "\n",
    "It will be *almost* exactly the same code, by using the [`cython`]() magic to have cells written in [Cython](http://cython.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A cell can now be written in Cython.\n",
    "For instance, we can define a simple example function in Python, and then write a Cython version, simply by declaring variables and tagging their types, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def some_loop(n: int) -> int:\n",
    "    s = 0\n",
    "    for i in range(0, n, 2):\n",
    "        s += i\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "def some_loop_cython(int n) -> int:\n",
    "    cdef int s = 0\n",
    "    cdef int i = 0\n",
    "    for i in range(0, n, 2):\n",
    "        s += i\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.95 s  90.8 ns per loop (mean  std. dev. of 7 runs, 1000000 loops each)\n",
      "14.6 s  528 ns per loop (mean  std. dev. of 7 runs, 100000 loops each)\n",
      "2.21 s  197 ns per loop (mean  std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.random.randint(1000)\n",
    "%timeit some_loop(np.random.randint(1000))\n",
    "%timeit some_loop_cython(np.random.randint(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KL divergences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "from libc.math cimport log\n",
    "eps = 1e-15  #: Threshold value: everything in [0, 1] is truncated to [eps, 1 - eps]\n",
    "\n",
    "def klBern_cython(float x, float y) -> float:\n",
    "    x = min(max(x, eps), 1 - eps)\n",
    "    y = min(max(y, eps), 1 - eps)\n",
    "    return x * log(x / y) + (1 - x) * log((1 - x) / (1 - y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "from libc.math cimport log\n",
    "eps = 1e-15  #: Threshold value: everything in [0, 1] is truncated to [eps, 1 - eps]\n",
    "\n",
    "def klBin_cython(float x, float y, int n) -> float:\n",
    "    x = min(max(x, eps), 1 - eps)\n",
    "    y = min(max(y, eps), 1 - eps)\n",
    "    return n * (x * log(x / y) + (1 - x) * log((1 - x) / (1 - y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "from libc.math cimport log\n",
    "eps = 1e-15  #: Threshold value: everything in [0, 1] is truncated to [eps, 1 - eps]\n",
    "\n",
    "def klPoisson_cython(float x, float y) -> float:\n",
    "    x = max(x, eps)\n",
    "    y = max(y, eps)\n",
    "    return y - x + x * log(x / y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "from libc.math cimport log\n",
    "eps = 1e-15  #: Threshold value: everything in [0, 1] is truncated to [eps, 1 - eps]\n",
    "\n",
    "def klExp_cython(float x, float y) -> float:\n",
    "    if x <= 0 or y <= 0:\n",
    "        return float('+inf')\n",
    "    else:\n",
    "        x = max(x, eps)\n",
    "        y = max(y, eps)\n",
    "        return x / y - 1 - log(x / y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gamma distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "from libc.math cimport log\n",
    "eps = 1e-15  #: Threshold value: everything in [0, 1] is truncated to [eps, 1 - eps]\n",
    "\n",
    "def klGamma_cython(float x, float y, float a=1) -> float:\n",
    "    if x <= 0 or y <= 0:\n",
    "        return float('+inf')\n",
    "    else:\n",
    "        x = max(x, eps)\n",
    "        y = max(y, eps)\n",
    "        return a * (x / y - 1 - log(x / y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative binomial distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "from libc.math cimport log\n",
    "eps = 1e-15  #: Threshold value: everything in [0, 1] is truncated to [eps, 1 - eps]\n",
    "\n",
    "def klNegBin_cython(float x, float y, float r=1) -> float:\n",
    "    x = max(x, eps)\n",
    "    y = max(y, eps)\n",
    "    return r * log((r + x) / (r + y)) - x * log(y * (r + x) / (x * (r + y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "from libc.math cimport log\n",
    "eps = 1e-15  #: Threshold value: everything in [0, 1] is truncated to [eps, 1 - eps]\n",
    "\n",
    "def klGauss_cython(float x, float y, float sig2x=0.25, float sig2y=0.25) -> float:\n",
    "    if - eps < (sig2y - sig2x) < eps:\n",
    "        return (x - y) ** 2 / (2. * sig2x)\n",
    "    else:\n",
    "        return (x - y) ** 2 / (2. * sig2y) + 0.5 * ((sig2x/sig2y)**2 - 1 - log(sig2x/sig2y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic KL-UCB indexes, with a bisection search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these, they need previously defined functions, which have to be rewritten from inside the `cython` cell to be accessible from Cython.\n",
    "To minimize repetitions, I use only one cell to define all functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "from libc.math cimport sqrt, log, exp\n",
    "eps = 1e-15  #: Threshold value: everything in [0, 1] is truncated to [eps, 1 - eps]\n",
    "\n",
    "\n",
    "def klucbGauss_cython(float x, float d, float sig2x=0.25, float precision=0.) -> float:\n",
    "    return x + sqrt(2 * sig2x * d)\n",
    "\n",
    "cdef float klucbGauss_cython_x(float x, float d, float sig2x=0.25, float precision=0.):\n",
    "    return x + sqrt(2 * sig2x * d)\n",
    "\n",
    "\n",
    "def klucb_cython(float x, float d, kl, float upperbound,\n",
    "                 float lowerbound=float('-inf'),\n",
    "                 float precision=1e-6, int max_iterations=50) -> float:\n",
    "    cdef float value = max(x, lowerbound)\n",
    "    cdef float u = upperbound\n",
    "    cdef int _count_iteration = 0\n",
    "    cdef float m = 0\n",
    "    while _count_iteration < max_iterations and u - value > precision:\n",
    "        _count_iteration += 1\n",
    "        m = (value + u) / 2.\n",
    "        if kl(x, m) > d:\n",
    "            u = m\n",
    "        else:\n",
    "            value = m\n",
    "    return (value + u) / 2.\n",
    "\n",
    "\n",
    "cdef float klBern_cython_x(float x, float y):\n",
    "    x = min(max(x, eps), 1 - eps)\n",
    "    y = min(max(y, eps), 1 - eps)\n",
    "    return x * log(x / y) + (1 - x) * log((1 - x) / (1 - y))\n",
    "\n",
    "def klucbBern_cython(float x, float d, float precision=1e-6) -> float:\n",
    "    cdef float upperbound = min(1., klucbGauss_cython_x(x, d, sig2x=0.25))  # variance 1/4 for [0,1] bounded distributions\n",
    "    # upperbound = min(1., klucbPoisson(x, d))  # also safe, and better ?\n",
    "    return klucb_cython(x, d, klBern_cython_x, upperbound, precision)\n",
    "\n",
    "\n",
    "cdef float klPoisson_cython_x(float x, float y):\n",
    "    x = max(x, eps)\n",
    "    y = max(y, eps)\n",
    "    return y - x + x * log(x / y)\n",
    "\n",
    "def klucbPoisson_cython(float x, float d, float precision=1e-6) -> float:\n",
    "    cdef float upperbound = x + d + sqrt(d * d + 2 * x * d)  # looks safe, to check: left (Gaussian) tail of Poisson dev\n",
    "    return klucb_cython(x, d, klPoisson_cython_x, upperbound, precision)\n",
    "\n",
    "\n",
    "cdef float klGamma_cython_x(float x, float y):\n",
    "    if x <= 0 or y <= 0:\n",
    "        return float('+inf')\n",
    "    else:\n",
    "        x = max(x, eps)\n",
    "        y = max(y, eps)\n",
    "        return x / y - 1 - log(x / y)\n",
    "\n",
    "def klucbExp_cython(float x, float d, float precision=1e-6) -> float:\n",
    "    cdef float upperbound = 1\n",
    "    cdef float lowerbound = 0\n",
    "    if d < 0.77:  # XXX where does this value come from?\n",
    "        upperbound = x / (1 + 2. / 3 * d - sqrt(4. / 9 * d * d + 2 * d))\n",
    "        # safe, klexp(x,y) >= e^2/(2*(1-2e/3)) if x=y(1-e)\n",
    "    else:\n",
    "        upperbound = x * exp(d + 1)\n",
    "    if d > 1.61:  # XXX where does this value come from?\n",
    "        lowerbound = x * exp(d)\n",
    "    else:\n",
    "        lowerbound = x / (1 + d - sqrt(d * d + 2 * d))\n",
    "    return klucb_cython(x, d, klGamma_cython_x, upperbound, lowerbound, precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, for `klucbBern_cython`, the two steps are to first compute an upperbound (as precise as possible) and the compute the kl-UCB index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.994140625"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9944823980331421"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.994140625"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9944896697998047"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, d = 0.9, 0.2\n",
    "upperbound = 1\n",
    "klucb_cython(x, d, klBern_cython, upperbound, lowerbound=0, precision=1e-3, max_iterations=10)\n",
    "klucb_cython(x, d, klBern_cython, upperbound, lowerbound=0, precision=1e-6, max_iterations=10)\n",
    "klucb_cython(x, d, klBern_cython, upperbound, lowerbound=0, precision=1e-3, max_iterations=50)\n",
    "klucb_cython(x, d, klBern_cython, upperbound, lowerbound=0, precision=1e-6, max_iterations=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Benchmarks\n",
    "\n",
    "For each of the functions defined in three approaches above, I will do some numerical tests to compare their speed  and memory   efficiency. Simple.\n",
    "\n",
    "The benchmark will be to test the computation time on random entries.\n",
    "It includes a constant time: creating random values! So I also compare the time to simply generate the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.random.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "617 ns  22.7 ns per loop (mean  std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit (r(), r())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KL divergences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.84 s  38.9 ns per loop (mean  std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klBern(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit klBern_numba(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952 ns  60 ns per loop (mean  std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klBern_cython(r(), r())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.52 s  528 ns per loop (mean  std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klBern(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952 ns  60 ns per loop (mean  std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klBern_numba(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952 ns  60 ns per loop (mean  std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klBern_cython(r(), r())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.52 s  528 ns per loop (mean  std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klBin(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952 ns  60 ns per loop (mean  std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klBin_numba(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952 ns  60 ns per loop (mean  std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klBin_cython(r(), r())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.52 s  528 ns per loop (mean  std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klPoisson(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952 ns  60 ns per loop (mean  std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klPoisson_numba(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952 ns  60 ns per loop (mean  std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klPoisson_cython(r(), r())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.52 s  528 ns per loop (mean  std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klExp(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952 ns  60 ns per loop (mean  std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klExp_numba(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952 ns  60 ns per loop (mean  std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klExp_cython(r(), r())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.52 s  528 ns per loop (mean  std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klGamma(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952 ns  60 ns per loop (mean  std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klGamma_numba(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952 ns  60 ns per loop (mean  std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klGamma_cython(r(), r())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.52 s  528 ns per loop (mean  std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klNegBin(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952 ns  60 ns per loop (mean  std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klNegBin_numba(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952 ns  60 ns per loop (mean  std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klNegBin_cython(r(), r())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.52 s  528 ns per loop (mean  std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klGauss(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952 ns  60 ns per loop (mean  std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klGauss_numba(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952 ns  60 ns per loop (mean  std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klGauss_cython(r(), r())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KL-UCB indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.52 s  528 ns per loop (mean  std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klucbGauss(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952 ns  60 ns per loop (mean  std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klucbGauss_numba(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952 ns  60 ns per loop (mean  std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klucbGauss_cython(r(), r())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.52 s  528 ns per loop (mean  std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klucbBern(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952 ns  60 ns per loop (mean  std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klucbBern_numba(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952 ns  60 ns per loop (mean  std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klucbBern_cython(r(), r())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.52 s  528 ns per loop (mean  std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klucbPoisson(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952 ns  60 ns per loop (mean  std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klucbPoisson_numba(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952 ns  60 ns per loop (mean  std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klucbPoisson_cython(r(), r())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.52 s  528 ns per loop (mean  std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klucbExp(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952 ns  60 ns per loop (mean  std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klucbExp_numba(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952 ns  60 ns per loop (mean  std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klucbExp_cython(r(), r())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Conclusion\n",
    "\n",
    "As expected, both the Numba and Cython versions are *way* faster than the naive Python versions, and Cython usually gives the best improvement.\n",
    "\n",
    "> That's it for today, folks! See [this page](https://github.com/Naereen/notebooks) for other notebooks I wrote recently."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "11px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": false,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "211px",
    "left": "987.125px",
    "right": "20px",
    "top": "97px",
    "width": "235px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
